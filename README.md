# ðŸ“˜ RAG Study Assistant â€” FAISS + Gemini + FastAPI + Cloud Run
**A document-based personal study assistant for students.**

This project allows a student to upload their **course lecture PDFs**, embed them using **FAISS**, and ask questions that are answered using **Google Gemini**, fully grounded in the course materials.

The system is ideal for courses where students must study using lecture slides, notes, or textbook PDFs â€” such as **Cloud Computing, Distributed Systems, Machine Learning**, etc.

![Rag Assistant](/assets/ragassistant.png)


## ðŸ› ï¸ Features

### ðŸ” Retrieval-Augmented Generation (RAG) 
- Retrieves relevant chunks from uploaded course materials. 
- Uses FAISS vector search for fast similarity lookup.

### ðŸ¤– Google Gemini LLM  
- Generates structured, high-quality English answers. 
- Includes improved prompting tuned for lecture/exam explanations.

### ðŸ“ Document-Based Q&A
- Answers are only generated using your PDFs (slides, notes).
- Works for any course â€” simply replace the documents.

### ðŸŒ Web UI  
- Clean, simple HTML frontend for asking questions.
- Shows retrieved passages + relevance scores.
Runs fully online via Cloud Run.

### â˜ï¸ Cloud Run Deployment 
- Backend downloads FAISS index & chunks from Google Cloud Storage at startup. 
- No local files needed on server.


## ðŸ“ Project Structure

```pgsql
rag-study-assistant/
â”‚
â”œâ”€â”€ data/                  # Local document & index storage (dev only)
â”‚   â”œâ”€â”€ *.pdf
â”‚   â”œâ”€â”€ chunks.json
â”‚   â”œâ”€â”€ embeddings.npy
â”‚   â”œâ”€â”€ faiss_index.bin
â”‚   â”œâ”€â”€ faiss_metadata.json
â”‚
â”œâ”€â”€ rag/
â”‚   â”œâ”€â”€ app.py             # FastAPI backend + Cloud Run startup logic
â”‚   â”œâ”€â”€ llm_wrapper.py     # Prompting + Gemini API wrapper
â”‚   â”œâ”€â”€ query_faiss.py     # Vector search over FAISS index
â”‚   â””â”€â”€ gcs_utils.py       # Download index from GCS
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingest.py          # Chunk PDFs â†’ chunks.json
â”‚   â”œâ”€â”€ embed_faiss.py     # Embed chunks â†’ FAISS index
â”‚   â””â”€â”€ eval_rag.py
â”‚
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ index.html         # Web UI served via FastAPI `/web`
â”‚
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .env
```

## Requirements

- Python 3.11+
- Google Cloud Account
- Gemini API Key
- Cloud Run enabled
- GCS bucket created

## Usage

### 1. Create `.env`

Create a `.env` file in the project root:

```ini
GEMINI_API_KEY=YOUR_KEY
GEMINI_MODEL_NAME=gemini-2.5-flash   # or another supported model
GCS_BUCKET_NAME=rag-documents-bucket-xxx
```


### 2. Setup Environment

```bash
python -m venv .venv
source .venv/bin/activate      # macOS/Linux
# .venv\Scripts\activate     # Windows

pip install -r requirements.txt
```


### 3. Add Course Documents

Place your `.pdf` files into:
```kotlin
data/*.pdf
```

For example:
```bash
data/lecture1.pdf
data/lecture2.pdf
data/chapter5.pdf
```

 When switching courses, simply delete old PDFs and upload new ones.


### 4. Ingest PDFs â†’ Chunks

```bash
python src/ingest.py
```

Generates:

```bash
data/chunks.json
```


### 5. Embed Chunks â†’ FAISS Index

```bash
python src/embed_faiss.py
```

Generates & uploads to GCS:

```bash
data/faiss_index.bin
data/faiss_metadata.json
data/chunks.json
data/embeddings.npy
```


### 6. Run Backend Locally

```bash
uvicorn rag.app:app --reload
```

Endpoints:

- Swagger â†’ http://127.0.0.1:8000/docs 
- Web UI â†’ http://127.0.0.1:8000/web 
- Health â†’ http://127.0.0.1:8000/health


### 7. Docker (Optional)

#### Build image:

```bash
docker build -t rag-app .
```

#### Run container:

```bash
docker run -p 8000:8000 --env-file .env rag-app
```


### 8. Deploy to Google Cloud Run

#### 8.1 Build & Push Docker Image:

```bash
gcloud builds submit \
  --tag europe-west1-docker.pkg.dev/YOUR_PROJECT_ID/rag-repo/rag-app
```

#### 8.2 Deploy to Cloud Run:

```bash
gcloud run deploy rag-service \
  --image europe-west1-docker.pkg.dev/YOUR_PROJECT_ID/rag-repo/rag-app \
  --platform managed \
  --region europe-west1 \
  --allow-unauthenticated \
  --set-env-vars GEMINI_API_KEY=YOUR_KEY,GEMINI_MODEL_NAME=gemini-2.0-flash,GCS_BUCKET_NAME=rag-documents-bucket-xxx
```

Cloud Run will output your service URL:

```bash
https://rag-service-xxxx-ew.a.run.app
```

You can now open:

```bash
https://rag-service-xxxx-ew.a.run.app/web
```


## Architecture - How the System Works
>#### 1. Student uploads PDFs (locally during ingestion)
>>PDFs â†’ text â†’ chunks.

>#### 2. Embeddings generated
>>Chunks â†’ embeddings â†’ FAISS index.

>#### 3. Index uploaded to GCS
>>Cloud Run always loads latest index.

>#### 4. FastAPI backend
>>Handles `/ask`:
>>>- retrieves top-k chunks
>>>- sends them to Gemini
>>>- returns structured English answer

>#### 5. Frontend UI
>>Shows:
>>>- Generated answer
>>>- Retrieval time
>>>- Passage list with scores

### Number of Passages (top-k)

In the web interface, you can choose how many document passages will be retrieved and used as context for Gemini.

- **top-k = 3** â†’ fast, short answers  
- **top-k = 5** â†’ recommended (balanced accuracy + speed)  
- **top-k = 7â€“10** â†’ more detailed, lecture-style answers

Higher values include more slides but may increase response time.


![Rag Question & Answer](/assets/mapreduceoutput.png)
![Rag Chunks](/assets/mapreducechunks.png)


## Ideal Use Case
This system is perfect for a student who wants:

- A personal AI assistant for one specific course
- Answers only from their lecture materials
- Quick re-indexing when switching courses
- Cloud deployment with zero local dependencies

Examples:

- "How does Map-Reduce work step-by-step?"
- "Summarize Lecture 3."
- "What is virtualization in cloud computing?"
- "What are AWS IAM roles?"


## Notes
- All answers are generated in English.

- Answers are grounded in retrieved PDFs; if unrelated, model says so.

- You can expand the frontend to allow file upload to GCS (future feature).

- Works with any course: you control the documents.

## License

Distributed under the **MIT License**.
